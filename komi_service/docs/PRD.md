## 1. 프로젝트 개요

### 서비스 개요

- **서비스명**: KOMI (Kinematic Optimization & Motion Intelligence)
- **목적**: AI 기반 실시간 관절 분석 및 LLM을 활용한 원격 진단·맞춤형 재활 운동 추천 시스템
- **핵심 기능**
    - 사용자가 제공된 운동 영상을 보고 따라하며 자세 분석 및 피드백 제공
    - LLM을 활용한 의료 상담 및 재활 운동 추천
    - 웹캠을 통한 실시간 자세 감지 및 교정 가이드

---

## 2. MVP 범위 (2주 개발 목표)

- Pose Detection 기반 실시간 자세 분석
- LLM 기반 의료 지식 응답 시스템 구축
- 웹캠을 통한 실시간 피드백 제공
- FastAPI + Streamlit을 이용한 최소 기능 UI 구축

---

## 3. 핵심 기능 정의

### 1. 실시간 관절 분석 (Pose Detection)

**기능 목표**
- YOLO11 기반 Pose Detection 모델을 활용하여 실시간 자세 분석
- 정상 자세와 비교하여 자세 정확도를 평가

**기술 요구 사항**
- YOLO11 pose detection 모델 적용
- 자세 비교 알고리즘
    - L2 Distance (관절 좌표 차이 비교)
    - Cosine Similarity (관절 벡터 유사도 분석)
    - Dynamic Time Warping (시간 축을 고려한 자세 비교)
- 자세 평가 기준 설정

**개발 범위**
- 카메라 입력을 받아 실시간으로 자세 분석
- 분석된 결과를 사용자에게 시각적으로 피드백 제공

---

### 2. LLM 기반 원격 진단 및 재활 운동 추천

**기능 목표**
- 사용자의 자세 분석 데이터를 기반으로 재활 운동 추천
- LLM을 활용하여 원격 진단 및 재활 지침 제공

**기술 요구 사항**
- Ollama 기반 LLM
- 재활 운동 및 의료 관련 데이터를 학습하여 맞춤형 운동 추천
- 모델의 설명 가능성 확보 → 사용자가 모델의 판단 근거를 이해할 수 있도록 설계

**개발 범위**
- LLM API 연결 및 질의 응답 기능 구현
- 사용자의 관절 데이터 기반 운동 추천 알고리즘 개발

---

### 3. 웹캠 연동 및 실시간 피드백

**기능 목표**
- 사용자가 운동을 수행하는 동안 실시간 카메라 입력을 통해 자세 분석
- 자세 분석 결과에 따른 실시간 피드백 제공

**기술 요구 사항**
- FastAPI + WebSocket을 활용한 실시간 데이터 스트리밍
- 다양한 환경(조명, 거리, 옷차림)에 대한 인식 성능 테스트
- 사용자가 인식되지 않거나 자세 분석이 불가능할 경우 오류 메시지 제공

**개발 범위**
- 웹캠 입력을 받아 FastAPI에서 처리하고 Streamlit에서 결과 시각화
- 분석 결과에 따른 즉각적인 사용자 피드백 제공

---

### 4. 사용자 피드백 및 UI/UX

**기능 목표**
- Streamlit 기반 프론트엔드 구축
- 사용자의 운동 데이터 분석 및 시각화

**기술 요구 사항**
- 운동 가이드 영상 제공
- 실시간 자세 분석 결과 표시 (백분율, 시각적 피드백)
- 사용자 운동 기록을 저장하고 결과 비교 가능하도록 구성

**개발 범위**
- FastAPI(백엔드) + Streamlit(프론트엔드) 연동
- 사용자 경험 최적화를 위한 UI/UX 설계

---

## 4. 기술 스택

백엔드: FastAPI, WebSocket, Python
프론트엔드: Streamlit
데이터 처리: YOLO11 Pose Detection, Ollama 기반 LLM
인프라: on-premise 서버

---

## 5. 서비스 데이터 플로우

1. 운동 선택
    a. 사용자가 운동을 클릭
    b. 화면에 운동 가이드 영상이 출력됨
    c. 운동 시작 클릭 시 사용자의 웹캠(정면, 측면)실행 및 웹캠 이미지가 서버에 전달 및 화면 출력
2. 정밀분석
    a. 사용자 시작 위치 감지 후 서버에 전달하는 웹캠 이미지에 카운트다운 추가(카메라 클라이언트)
    b. 운동 시작: 사용자가 운동을 진행하고 웹캠 영상이 녹화됨(카메라 클라이언트)
    c. 운동 종료: 일정 시간이 지나면 영상 녹화가 끝나고 해당 영상을 서버로 전달(카메라 클라이언트)
    d. 정밀분석 진행(서버): 
        - 사용자 영상에서 좌표 추출
        - 정답 영상 좌표와 비교
        - RAG 진행 및 피드백 생성(정확한 자세를 위한 조언)
    e. 결과 출력: 사용자의 영상과 분석된 결과를 화면에 출력
3. 실시간 분석
    a. 웹캠 이미지와 함께 관절 좌표가 서버에 전달(관절 좌표 추출은 우선 초당 1번)
        - 웹캠 이미지 전달 함수에 관절 좌표 추출 여부 옵션, 관절 좌표 추출 간격 옵션 추가
    b. 정답 관절 좌표와 비교하여 자세 점수를 계산(서버)
    c. 웹캠 이미지와 실시간 피드백(자세 점수)을 화면에 출력
        - 시각화 방안 고려

---

## 6. 일정 계획 (2주 MVP 개발)

1주차:
- FastAPI 백엔드 개발 (WebSocket 포함)
- Pose Detection 모델 테스트 및 튜닝
- LLM 기반 운동 추천 시스템 기본 구축

2주차:
- Streamlit 기반 UI 개발 및 백엔드 연동
- 실시간 피드백 기능 구현 및 테스트
- 최종 디버깅 및 MVP 배포
